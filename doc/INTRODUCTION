

***** Getting Started ******

RegAligner requires as input a list of source sentences and a list of target sentences. In
both cases, the lists are INDICES, i.e. positive integers (0 is reserved for the empty word). 
It then estimates p(source | target) based on models derived from the models IBM 1-5 and HMM. 

Here is a sample call that estimates p(German | English):

regaligner_swb.opt.L64 -s de.idx -t en.idx -oa alignments.final

The estimated alignments are written to the file alignments.final .

To get your input files into the required format, please take a look at 
the binaries 

extractvoc.opt.L64       and
plain2indices.opt.L64

that are included in RegAligner.

***** Default behavior ****

By default, RegAligner runs 5 EM-iterations of the IBM-1, then 5 of the HMM, 5 of the IBM-3 and 5 of the IBM-4. 
By default no regularity terms are used.

For IBM-3/4/5, the default initialization of the models is a specific estimation. If you want to use count collection 
as proposed by [Brown et al. 1993], add

-count-collection

to the command line. In future versions the default behaviour may change.

***** Enabling reading of zipped files ****

To enable reading of zipped files (presently these can only be the corpus
files, i.e. no dictionaries etc.), you need to download the gzstream classes
from the University of North Carolina: http://www.cs.unc.edu/Research/compgeom/gzstream/ 
and make sure that you have permission to use them. Afterward, add -DHAS_GZSTREAM to the 
compiler options and make sure that you link against gzstream.

***** Changing output behavior ****

Apart from the final alignments, so far only the computed dictionary can be output.
To this end, add 

-o dict.final

(or any other filename) to the command line.

***** Activating posterior decoding *****

By default the written alignments are Viterbi alignments (modes of the distribution). 
To activate posterior decoding, add

-postdec-thresh 0.25

(or another positive value smaller than 1) to the command line. If the given
threshold is <= 0.5 you may get several alignments for some source words, even
though this violates the assumptions in the implemented models.

***** Changing the number of iterations ****

To change the number of iterations run for a model, add the options

-ibm1-iter <uint>
-ibm2-iter <uint>
-hmm-iter <uint>
-ibm3-iter <uint>
-ibm4-iter <uint>
-ibm5-iter <uint>

to the command line (replace <uint> by the desired number).

***** Changing run-time and memory consumption ******

If you use EM (rather than gradient descent or Viterbi) you can reduce the
run-time of IBM-1, IBM-2 and HMM by adding the option

-dont-print-energy

to the command line. You will then no longer see an energy printout after
every iteration.


If you want to reduce memory consumption, add 

-max-lookup 400

(or some other number) to the command line. By default, RegAligner stores a
dictionary lookup table for every sentence pair, where a pair with J source
words and I target words needs I*J lookup entries. If you add -max-lookup 400, 
RegAligner will only store tables for sentence pairs with I*J <= 400. The
tables for the other pairs are computed on the fly. Naturally, this takes
quite some extra running time.


***** Changing the type of HMM *****

you can experiment with how exactly the HMM model is parameterized by exploring the options

-hmm-type (auto | fullpar | redpar | nonpar | nonpar2)

and 

-hmm-init-type (auto | par | nonpar | fix | fix2)

***** Using word classes for IBM-4 and IBM-5 *****

To use wordclasses for HMM, IBM-4 and IBM-5, add 

-sclasses <file> -tclasses <file>

to the command line. IBM-5 will ignore target classes. The HMM will be run without classes if you add
-no-h3-classes

CAUTION: the required format differs from GIZA++. Use the program cls2rac 
included in this compilation to convert files generated by mkcls to the required format.

***** Using nondeficient and reduced deficient variants of IBM-3 and IBM-4 ******

if you want to use the nondeficient variants of IBM-3 and IBM-4 as in 
[Schoenemann, ACL 2013], add

-nondeficient

to the command line options

If you want to merely reduce deficiency as in the paper, add

-reduce-deficiency 

to the command line. The run times and the memory consumption will be much
 higher than in normal mode (at least if you use word classes), but still much
 less than in nondeficient mode

***** Evaluating on gold alignments for the training set ****

RegAligner supports the option to evaluate intermediate alignments (arising
during the iterations) on gold alignments for the training set. These
alignments are used solely for outputting error/accuracy measures. They do not
influence the computed alignments.

To pass in gold alignments, add

-refa <filename>

to the command line. For the general format see sample.refa (in the directory
doc). Here target indices are listed first. To swap the roles of source and
target, add

-invert-biling-data

to the command line.

***** Notes on the computed alignments *****

For the fertility models, the printed Viterbi error rates are always for the last alignments (computed by hillclimbing)
In contrast, the Posterior error rates (shown only in EM mode) are for the latest parameters.

Also note that the alignments printed to file are for the latest parameters. If you want those evaluated earlier, you
have to run one iteration less.

***** Computing alignments on additional data *****

It is possible to also compute alignments on data that are not to be
used for the training of the models (e.g. a development set). This is done
simultaneously with the training. To this end add

-ds <additional source file> -dt <additional target file>

to the command line, e.g. as here:

regaligner_swb.opt.L64 -s de.idx -t en.idx -ds dev.de.idx -dt dev.en.idx  -oa alignments.final

The alignments on the additional data will then be written to the file
 alignments.final.dev

CAREFUL: the training set and the additional set need to use the SAME set of word indices.

***** Activating Penalization of Mass ****

to activate the penalization of mass as in [Schoenemann, IJCNLP 2011],
add 

-sparse-reg -dict-regularity 2.5

(or any other value) to the command line. Make sure that you are NOT using
Viterbi training (e.g. that -method gets the default value of "em").

***** Activating EM-Training with L0-terms ***

to do this, add

-dict-regularity 5.0 -l0-beta 0.1

(or comparable values)

***** Viterbi-training with or without L0-terms ****

To activate Viterbi training (with ICM-stages as in [Schoenemann, CoNLL
2011]), add

-method viterbi

to the command line. If you further wish to activate the L0-regularity (which
is recommended for Viterbi training), add 

-dict-regularity 5.0

(or any other value) to the command line.

****** Using gradient descent instead of EM ****

Using gradient descent has been shown to be inferior to using EM [Schoenemann,
IJCNLP 2011]. If you want to test it nonetheless, add

-method gd 

to the command line.


***** Regularizers based on prior dictionary knowledge ****

RegAligner supports the possibility to use regularizers based on
prior dictionaries. These dictionaries contain per line one possible 
constellation of source and target index, in the form

<target word idx> <source word idx>

The regularity weight for this constellation is set to 0. To pass a dictionary
to RegAligner, add

-prior-dict <filename>

to the command line. If your dictionary contains entries in the form <source> <target>,
add

-invert-biling-data

to the command line. ATTENTION: this will swap source and target for gold alignments, too.

********** Training with ITG and IBM constraints ***********

This is not recommended, and only available for the IBM-3 (which will run in Viterbi mode). If you want to use it:

For ITG constraints add 

-constraint-mode itg

with the additional options:
-itg-max-mid-dev <uint>
-itg-ext-level <uint> (0-4 are implemented)
-ibm-max-skip <uint> (only active for itg-ext-level 4, you will find that only values up to 4 are manageable)

For IBM constraints add

-constraint-mode ibm

with the additional option:
-ibm-max-skip <uint> (you will find that only values up to 3 are manageable)
