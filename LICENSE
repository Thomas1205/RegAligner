This software (except for the C++-Toolbox) was exclusively written by 

Thomas Schoenemann.

The code was written in roughly equal parts in his freetime, at Lund
University, Sweden and at the University of Düsseldorf, Germany. A few
contributions were added at the University of Pisa, Italy. and at the
University of Düsseldorf, Germany. The package includes a recent (partial)
version of the C++-Toolbox by Thomas Schoenemann, which received additional
support from Petter Strandmark and Miriam Käshammer.


The user is granted access to this software under the following conditions:

1. The software is provided "as is" by the author, with absolutely no actual
or implied warranty of correctness, fitness, intellectual property ownership,
or anything else whatsoever. You use the software entirely at your own
risk. In no event shall the author be liable for any direct, indirect or
perceived damage whatsoever connected with the use of this work.

2. The user is granted permission to use this software for any kind of
research purposes, e.g. in academia, in an industrial setting or in a private
setting. Commercial usage of this code is however strictly prohibited. That
is, this software may not be used for software packages that are charged for
in any way.

3. The user is free to distribute this code as long as this is free of charge
and he/she indicates the original author and also distributes this license.

4. The user is granted the right to modify the code to suit his/her own
needs. The author appreciates to be informed about useful modifications. It is
allowed, but not required, to make these changes publicly available.

5. If you use this software for publications, please consider if citing one
(or more) of the following papers is appropriate:

- [T. Schoenemann, Probabilistic Word Alignment Under the L_0-norm, CoNLL 2011.]
(relevant in combination with Viterbi-training)

- [T. Schoenemann, Regularizing Mono- and Bi-word Models for Word Alignment, IJCNLP 2011.]
(relevant when using gradient descent or EM with regularity terms, 
or when emphasis on the corrected HMM training is appropriate)

- if you use L_0 in combination with EM:
[A. Vaswani and L. Huang and D. Chiang, Smaller Alignment Models for Better
Translations: Unsupervised Word Alignment with the L0-norm. ACL 2012.]
